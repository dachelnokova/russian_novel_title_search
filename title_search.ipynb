{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Javvwrt5EDnJ"
      },
      "source": [
        "# Поиск по заглавиям романов"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## инсталы"
      ],
      "metadata": {
        "id": "l5t8vstNpE98"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jqy9DBydQ-O",
        "outputId": "91ad2446-4718-4bc5-86ea-540389b88b12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Collecting dawg-python>=0.7.1 (from pymorphy2)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting docopt>=0.6 (from pymorphy2)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=930326e8a26f1b23139db6eee98ee092bfe0339317ba1a0356130acd9e1efe38\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, xxhash, pymorphy2, pyarrow, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.6.1\n",
            "    Uninstalling fsspec-2024.6.1:\n",
            "      Successfully uninstalled fsspec-2024.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.3.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.5.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dawg-python-0.7.2 dill-0.3.8 docopt-0.6.2 fsspec-2024.5.0 multiprocess-0.70.16 pyarrow-17.0.0 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers scikit-learn nltk pymorphy2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5zby1VgudQ-W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import nltk\n",
        "import pymorphy2\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import torch\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "FUZikxngEc00",
        "outputId": "60ac1c97-b8dd-4fae-a26e-196fdc8b2272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0  Награждённая постоянность, или Приключения Лиз...   \n",
              "1     Непостоянная фортуна, или Похождения Мирамонда   \n",
              "2  Приключения Фемистокла и разные политические, ...   \n",
              "3                 Пересмешник, или Славенские сказки   \n",
              "4                           Письма Эрнеста и Доравры   \n",
              "\n",
              "                                     processed_title  \n",
              "0  наградить постоянность приключение лизарка сар...  \n",
              "1           непостоянный фортуна похождение мирамонд  \n",
              "2  приключение фемистокнуть разный политический г...  \n",
              "3                      пересмешник славенский сказка  \n",
              "4                               письмо эрнест доравр  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93441501-356e-4172-8b57-ab05357f67d8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>processed_title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Награждённая постоянность, или Приключения Лиз...</td>\n",
              "      <td>наградить постоянность приключение лизарка сар...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Непостоянная фортуна, или Похождения Мирамонда</td>\n",
              "      <td>непостоянный фортуна похождение мирамонд</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Приключения Фемистокла и разные политические, ...</td>\n",
              "      <td>приключение фемистокнуть разный политический г...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Пересмешник, или Славенские сказки</td>\n",
              "      <td>пересмешник славенский сказка</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Письма Эрнеста и Доравры</td>\n",
              "      <td>письмо эрнест доравр</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93441501-356e-4172-8b57-ab05357f67d8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-93441501-356e-4172-8b57-ab05357f67d8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-93441501-356e-4172-8b57-ab05357f67d8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dfe8a4b7-b555-4bc9-a75a-6fe44538a76a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dfe8a4b7-b555-4bc9-a75a-6fe44538a76a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dfe8a4b7-b555-4bc9-a75a-6fe44538a76a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data[['title', 'processed_title']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u041d\\u0435\\u043f\\u043e\\u0441\\u0442\\u043e\\u044f\\u043d\\u043d\\u0430\\u044f \\u0444\\u043e\\u0440\\u0442\\u0443\\u043d\\u0430, \\u0438\\u043b\\u0438 \\u041f\\u043e\\u0445\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u044f \\u041c\\u0438\\u0440\\u0430\\u043c\\u043e\\u043d\\u0434\\u0430\",\n          \"\\u041f\\u0438\\u0441\\u044c\\u043c\\u0430 \\u042d\\u0440\\u043d\\u0435\\u0441\\u0442\\u0430 \\u0438 \\u0414\\u043e\\u0440\\u0430\\u0432\\u0440\\u044b\",\n          \"\\u041f\\u0440\\u0438\\u043a\\u043b\\u044e\\u0447\\u0435\\u043d\\u0438\\u044f \\u0424\\u0435\\u043c\\u0438\\u0441\\u0442\\u043e\\u043a\\u043b\\u0430 \\u0438 \\u0440\\u0430\\u0437\\u043d\\u044b\\u0435 \\u043f\\u043e\\u043b\\u0438\\u0442\\u0438\\u0447\\u0435\\u0441\\u043a\\u0438\\u0435, \\u0433\\u0440\\u0430\\u0436\\u0434\\u0430\\u043d\\u0441\\u043a\\u0438\\u0435, \\u0444\\u0438\\u043b\\u043e\\u0441\\u043e\\u0444\\u0438\\u0447\\u0435\\u0441\\u043a\\u0438\\u0435, \\u0444\\u0438\\u0437\\u0438\\u0447\\u0435\\u0441\\u043a\\u0438\\u0435 \\u0438 \\u0432\\u043e\\u0435\\u043d\\u043d\\u044b\\u0435 \\u0435\\u0433\\u043e \\u0441 \\u0441\\u044b\\u043d\\u043e\\u043c \\u0441\\u0432\\u043e\\u0438\\u043c \\u0440\\u0430\\u0437\\u0433\\u043e\\u0432\\u043e\\u0440\\u044b, \\u043f\\u043e\\u0441\\u0442\\u043e\\u044f\\u043d\\u043d\\u0430\\u044f \\u0436\\u0438\\u0437\\u043d\\u044c \\u0438 \\u0436\\u0435\\u0441\\u0442\\u043e\\u043a\\u043e\\u0441\\u0442\\u044c \\u0444\\u043e\\u0440\\u0442\\u0443\\u043d\\u044b, \\u0435\\u0433\\u043e \\u0433\\u043e\\u043d\\u044f\\u0449\\u0435\\u0439\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"processed_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u043d\\u0435\\u043f\\u043e\\u0441\\u0442\\u043e\\u044f\\u043d\\u043d\\u044b\\u0439 \\u0444\\u043e\\u0440\\u0442\\u0443\\u043d\\u0430 \\u043f\\u043e\\u0445\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u0435 \\u043c\\u0438\\u0440\\u0430\\u043c\\u043e\\u043d\\u0434\",\n          \"\\u043f\\u0438\\u0441\\u044c\\u043c\\u043e \\u044d\\u0440\\u043d\\u0435\\u0441\\u0442 \\u0434\\u043e\\u0440\\u0430\\u0432\\u0440\",\n          \"\\u043f\\u0440\\u0438\\u043a\\u043b\\u044e\\u0447\\u0435\\u043d\\u0438\\u0435 \\u0444\\u0435\\u043c\\u0438\\u0441\\u0442\\u043e\\u043a\\u043d\\u0443\\u0442\\u044c \\u0440\\u0430\\u0437\\u043d\\u044b\\u0439 \\u043f\\u043e\\u043b\\u0438\\u0442\\u0438\\u0447\\u0435\\u0441\\u043a\\u0438\\u0439 \\u0433\\u0440\\u0430\\u0436\\u0434\\u0430\\u043d\\u0441\\u043a\\u0438\\u0439 \\u0444\\u0438\\u043b\\u043e\\u0441\\u043e\\u0444\\u0438\\u0447\\u0435\\u0441\\u043a\\u0438\\u0439 \\u0444\\u0438\\u0437\\u0438\\u0447\\u0435\\u0441\\u043a\\u0438\\u0439 \\u0432\\u043e\\u0435\\u043d\\u043d\\u044b\\u0439 \\u0441\\u044b\\u043d \\u0441\\u0432\\u043e\\u0439 \\u0440\\u0430\\u0437\\u0433\\u043e\\u0432\\u043e\\u0440 \\u043f\\u043e\\u0441\\u0442\\u043e\\u044f\\u043d\\u043d\\u044b\\u0439 \\u0436\\u0438\\u0437\\u043d\\u044c \\u0436\\u0435\\u0441\\u0442\\u043e\\u043a\\u043e\\u0441\\u0442\\u044c \\u0444\\u043e\\u0440\\u0442\\u0443\\u043d\\u0430 \\u0433\\u043d\\u0430\\u0442\\u044c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "url = 'https://raw.githubusercontent.com/dachelnokova/rus_novel_title/main/rus_novel_titles.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# предобработка текста\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "russian_stopwords = set(stopwords.words('russian'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    words = nltk.word_tokenize(text.lower())\n",
        "    words = [morph.parse(word)[0].normal_form for word in words if word.isalnum()]\n",
        "    words = [word for word in words if word not in russian_stopwords]\n",
        "    return ' '.join(words)\n",
        "\n",
        "# подготовка данных\n",
        "data['processed_title'] = data['title'].apply(preprocess_text)\n",
        "data[['title', 'processed_title']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymg9mUyNFBsf"
      },
      "source": [
        "## 1. Полнотекстовый поиск (Tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "eDxWy_LUFBsf"
      },
      "outputs": [],
      "source": [
        "# 1. полнотекстовый поиск\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(data['processed_title'])\n",
        "\n",
        "def full_text_search(query, top_k=5):\n",
        "    processed_query = preprocess_text(query)\n",
        "    query_vec = vectorizer.transform([processed_query])\n",
        "    similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
        "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "    return [(data.iloc[i]['title'], similarities[i]) for i in top_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aLLEcGqFBsg"
      },
      "outputs": [],
      "source": [
        "# import joblib\n",
        "# joblib.dump(tfidf_matrix, 'tfidf_matrix.pkl')\n",
        "# joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtJzr8vDUKo9"
      },
      "source": [
        "## 2. Векторный поиск (sberbank-ai/sbert_large_nlu_ru)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "JlZpM0V8UKo-"
      },
      "outputs": [],
      "source": [
        "# 2. векторный поиск\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/sbert_large_nlu_ru\")\n",
        "model = AutoModel.from_pretrained(\"sberbank-ai/sbert_large_nlu_ru\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "OP3r757DUKo-"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybeMVHwxUKo-",
        "outputId": "65c34cf0-34d9-4631-bc9c-b50bf64b131b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(120138, 1024, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 1024)\n",
              "    (token_type_embeddings): Embedding(2, 1024)\n",
              "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-23): 24 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSdpaSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "TVEr3lZXUKo_"
      },
      "outputs": [],
      "source": [
        "def get_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "3ITXhnN_UKo_"
      },
      "outputs": [],
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "_Lb88EnPUKo_"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "fm3S1RlTUKpA"
      },
      "outputs": [],
      "source": [
        "def compute_embedding(text):\n",
        "    return get_embedding(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXiTpiUHUKpA",
        "outputId": "942fa3d5-ee4a-4b00-ff0e-6c546716edba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing embeddings: 100%|██████████| 2036/2036 [10:39<00:00,  3.19it/s]\n"
          ]
        }
      ],
      "source": [
        "# создание эмбеддингов для всех документов\n",
        "from multiprocessing import Pool, cpu_count\n",
        "\n",
        "def create_document_embeddings(texts, processes=None):\n",
        "    with Pool(processes=processes or cpu_count()) as pool:\n",
        "        document_embeddings = list(tqdm(pool.imap(compute_embedding, texts), total=len(texts), desc=\"Processing embeddings\"))\n",
        "    return np.array(document_embeddings)\n",
        "\n",
        "# gpu\n",
        "# def create_document_embeddings(texts, max_workers=4):\n",
        "#     document_embeddings = []\n",
        "\n",
        "#     with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
        "#         futures = [executor.submit(compute_embedding, text) for text in texts]\n",
        "#         for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing embeddings\"):\n",
        "#             document_embeddings.append(future.result())\n",
        "\n",
        "#     return np.array(document_embeddings)\n",
        "\n",
        "\n",
        "# вызов функции с данными\n",
        "document_embeddings = create_document_embeddings(data['title'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "dMJgiEiDUKpA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e43c3c4b-4e96-41d4-e4a6-730c00f5827a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.001265  , -0.46314391, -0.23325287, ...,  0.02570524,\n",
              "         0.6384671 , -0.04932671],\n",
              "       [ 0.7336704 , -0.4700265 , -0.26066113, ...,  0.22309197,\n",
              "         0.34124857, -0.13451265],\n",
              "       [ 0.7241792 , -0.40413648, -0.8195384 , ..., -0.10955931,\n",
              "         0.9635812 , -0.1345805 ],\n",
              "       ...,\n",
              "       [ 0.470502  , -0.1615254 , -0.46566772, ..., -0.28230423,\n",
              "        -0.64112973,  0.5520886 ],\n",
              "       [ 0.6015674 , -0.38889933, -0.8934784 , ..., -0.2547407 ,\n",
              "        -0.00893512, -0.03332439],\n",
              "       [ 0.08298261, -0.2955161 , -0.81802297, ..., -0.18663372,\n",
              "        -0.4014135 ,  0.19867627]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "document_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# нормализация эмбеддингов\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "normalized_embeddings = normalize(document_embeddings)"
      ],
      "metadata": {
        "id": "NueZLg2Qk3sr"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_embeddings"
      ],
      "metadata": {
        "id": "nf2vk266lNYe",
        "outputId": "e1c1dc51-235f-4679-f25f-0a4434637851",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.06239568, -0.02886167, -0.01453558, ...,  0.00160187,\n",
              "         0.03978725, -0.00307388],\n",
              "       [ 0.04491978, -0.02877789, -0.01595926, ...,  0.01365905,\n",
              "         0.02089332, -0.00823569],\n",
              "       [ 0.04140471, -0.02310637, -0.04685684, ..., -0.00626402,\n",
              "         0.05509244, -0.0076946 ],\n",
              "       ...,\n",
              "       [ 0.027622  , -0.00948276, -0.0273382 , ..., -0.01657338,\n",
              "        -0.03763913,  0.03241175],\n",
              "       [ 0.03837259, -0.02480699, -0.05699291, ..., -0.01624932,\n",
              "        -0.00056995, -0.00212569],\n",
              "       [ 0.00535637, -0.01907502, -0.05280187, ..., -0.01204686,\n",
              "        -0.0259105 ,  0.01282419]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('sbert_large_nlu_ru_embeddings.npy', normalized_embeddings)"
      ],
      "metadata": {
        "id": "9jFj-7-YlRmK"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sbert_embeddings = np.load('sbert_large_nlu_ru_embeddings.npy')"
      ],
      "metadata": {
        "id": "yxo3pevIl9di"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4gF4x_PUKpB"
      },
      "outputs": [],
      "source": [
        "# !ls /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "FGd27nZkUKpB"
      },
      "outputs": [],
      "source": [
        "def vector_search(query, top_k=5):\n",
        "      # используем оригинальный запрос без предобработки\n",
        "    query_vec = get_embedding(query)\n",
        "    similarities = cosine_similarity([query_vec], sbert_embeddings).flatten()\n",
        "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "    return [(data.iloc[i]['title'], similarities[i]) for i in top_indices]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTqvCsKrH2HQ"
      },
      "source": [
        "## 3. Гибридный поиск"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "Vslj8g0CH2HQ"
      },
      "outputs": [],
      "source": [
        "# 3. гибридный поиск\n",
        "def hybrid_search(query, top_k=5, weight_full_text=0.5):\n",
        "    full_text_results = full_text_search(query, top_k)\n",
        "    vector_results = vector_search(query, top_k)\n",
        "\n",
        "    combined_results = {}\n",
        "    for doc, score in full_text_results:\n",
        "        combined_results[doc] = weight_full_text * score\n",
        "\n",
        "    for doc, score in vector_results:\n",
        "        if doc in combined_results:\n",
        "            combined_results[doc] += (1 - weight_full_text) * score\n",
        "        else:\n",
        "            combined_results[doc] = (1 - weight_full_text) * score\n",
        "\n",
        "    sorted_results = sorted(combined_results.items(), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_results[:top_k]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zluxnSezFU2n"
      },
      "source": [
        "## Проверка как работает"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "TQpbNv68FU2o"
      },
      "outputs": [],
      "source": [
        "def perform_search(query, top_k, method):\n",
        "    start_time = time.time()\n",
        "\n",
        "    if method == 'full_text':\n",
        "        results = full_text_search(query, top_k)\n",
        "    elif method == 'vector':\n",
        "        results = vector_search(query, top_k)\n",
        "    elif method == 'hybrid':\n",
        "        results = hybrid_search(query, top_k)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid search method. Choose from 'full_text', 'vector', 'hybrid'.\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    # нумерация результатов\n",
        "    numbered_results = [(i + 1, doc, score) for i, (doc, score) in enumerate(results)]\n",
        "\n",
        "    print(f\"\\nВаш поисковой запрос: {query}\")\n",
        "    print(f\"Выбранный метод поиска: {method}\")\n",
        "    print(f\"Количество результатов для выдачи: {top_k}\")\n",
        "    print(f\"Время исполнения: {elapsed_time:.4f} секунд\")\n",
        "    print(\"-\" * 34)\n",
        "\n",
        "    for i, doc, score in numbered_results:\n",
        "        print(f\"{i}. Скор:  {score:.4f}\")\n",
        "        print(f\"Заглавие: {doc}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Отцы и дети"
      ],
      "metadata": {
        "id": "_EBeJxLVo37j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jYPjNufFZqy",
        "outputId": "d03907d8-4626-48af-b840-d80ebac70a3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ваш поисковой запрос: Отцы и дети\n",
            "Выбранный метод поиска: full_text\n",
            "Количество результатов для выдачи: 5\n",
            "Время исполнения: 0.0214 секунд\n",
            "----------------------------------\n",
            "1. Скор:  1.0000\n",
            "Заглавие: Отцы и дети\n",
            "\n",
            "2. Скор:  0.7284\n",
            "Заглавие: Дети\n",
            "\n",
            "3. Скор:  0.5384\n",
            "Заглавие: Дети земли\n",
            "\n",
            "4. Скор:  0.4754\n",
            "Заглавие: Нежеланные дети\n",
            "\n",
            "5. Скор:  0.4694\n",
            "Заглавие: За грехи отца\n",
            "\n"
          ]
        }
      ],
      "source": [
        "perform_search(\"Отцы и дети\", 5, 'full_text')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perform_search(\"Отцы и дети\", 5, 'vector')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwEnGFMjcQpX",
        "outputId": "e21f8ece-6ac3-48b1-c109-78d869ed3c02"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ваш поисковой запрос: Отцы и дети\n",
            "Выбранный метод поиска: vector\n",
            "Количество результатов для выдачи: 5\n",
            "Время исполнения: 3.0316 секунд\n",
            "----------------------------------\n",
            "1. Скор:  1.0000\n",
            "Заглавие: Отцы и дети\n",
            "\n",
            "2. Скор:  0.8550\n",
            "Заглавие: Мать и дочь\n",
            "\n",
            "3. Скор:  0.8415\n",
            "Заглавие: Мужья и жёны\n",
            "\n",
            "4. Скор:  0.8145\n",
            "Заглавие: Дед и внук\n",
            "\n",
            "5. Скор:  0.8087\n",
            "Заглавие: Дети\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perform_search(\"Отцы и дети\", 5, 'hybrid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67GxvmL4c1R5",
        "outputId": "b40b19ac-81bc-4b04-bb0c-57bc3ad26de8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ваш поисковой запрос: Отцы и дети\n",
            "Выбранный метод поиска: hybrid\n",
            "Количество результатов для выдачи: 5\n",
            "Время исполнения: 0.3202 секунд\n",
            "----------------------------------\n",
            "1. Скор:  1.0000\n",
            "Заглавие: Отцы и дети\n",
            "\n",
            "2. Скор:  0.7685\n",
            "Заглавие: Дети\n",
            "\n",
            "3. Скор:  0.4275\n",
            "Заглавие: Мать и дочь\n",
            "\n",
            "4. Скор:  0.4208\n",
            "Заглавие: Мужья и жёны\n",
            "\n",
            "5. Скор:  0.4073\n",
            "Заглавие: Дед и внук\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### мяу"
      ],
      "metadata": {
        "id": "kWH2UFKVo0Lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perform_search(\"мяу\", 5, 'full_text')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3sST-IleHao",
        "outputId": "93973b68-acc1-4854-e01c-660aa5adae7d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ваш поисковой запрос: мяу\n",
            "Выбранный метод поиска: full_text\n",
            "Количество результатов для выдачи: 5\n",
            "Время исполнения: 0.0058 секунд\n",
            "----------------------------------\n",
            "1. Скор:  0.0000\n",
            "Заглавие: Моя весна\n",
            "\n",
            "2. Скор:  0.0000\n",
            "Заглавие: Идеалисты и реалисты\n",
            "\n",
            "3. Скор:  0.0000\n",
            "Заглавие: Царский суд\n",
            "\n",
            "4. Скор:  0.0000\n",
            "Заглавие: Мещане\n",
            "\n",
            "5. Скор:  0.0000\n",
            "Заглавие: Убийца\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perform_search(\"мяу\", 5, 'vector')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPPL-WxMeHko",
        "outputId": "a17f72c5-131a-4fbb-df11-ce79e6df6b0a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ваш поисковой запрос: мяу\n",
            "Выбранный метод поиска: vector\n",
            "Количество результатов для выдачи: 5\n",
            "Время исполнения: 0.2660 секунд\n",
            "----------------------------------\n",
            "1. Скор:  0.6423\n",
            "Заглавие: Муся\n",
            "\n",
            "2. Скор:  0.6285\n",
            "Заглавие: Мура\n",
            "\n",
            "3. Скор:  0.6238\n",
            "Заглавие: Мимочка\n",
            "\n",
            "4. Скор:  0.5934\n",
            "Заглавие: Котик Летаев\n",
            "\n",
            "5. Скор:  0.5784\n",
            "Заглавие: Мыканье\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perform_search(\"мяу\", 5, 'hybrid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHwQ6N5ieLzh",
        "outputId": "1ccf81e4-2067-41e7-a621-5ee404ba46f2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ваш поисковой запрос: мяу\n",
            "Выбранный метод поиска: hybrid\n",
            "Количество результатов для выдачи: 5\n",
            "Время исполнения: 0.3224 секунд\n",
            "----------------------------------\n",
            "1. Скор:  0.3211\n",
            "Заглавие: Муся\n",
            "\n",
            "2. Скор:  0.3142\n",
            "Заглавие: Мура\n",
            "\n",
            "3. Скор:  0.3119\n",
            "Заглавие: Мимочка\n",
            "\n",
            "4. Скор:  0.2967\n",
            "Заглавие: Котик Летаев\n",
            "\n",
            "5. Скор:  0.2892\n",
            "Заглавие: Мыканье\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### уют"
      ],
      "metadata": {
        "id": "7-8Ux2HuowvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perform_search(\"уют\", 5, 'full_text')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "173e6222-2a8e-403c-9216-0681bd01e078",
        "id": "GO07iPBRfbEd"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Выполняется полнотекстовый поиск...\n",
            "Предобработка текста: уют\n",
            "Полнотекстовый поиск завершен.\n",
            "\n",
            "Ваш поисковой запрос: уют\n",
            "Выбранный метод поиска: full_text\n",
            "Количество результатов для выдачи: 5\n",
            "Время исполнения: 0.0193 секунд\n",
            "----------------------------------\n",
            "1. Скор:  0.0000\n",
            "Заглавие: Моя весна\n",
            "\n",
            "2. Скор:  0.0000\n",
            "Заглавие: Идеалисты и реалисты\n",
            "\n",
            "3. Скор:  0.0000\n",
            "Заглавие: Царский суд\n",
            "\n",
            "4. Скор:  0.0000\n",
            "Заглавие: Мещане\n",
            "\n",
            "5. Скор:  0.0000\n",
            "Заглавие: Убийца\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perform_search(\"уют\", 5, 'vector')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7a7131a-d40f-45fb-f4a2-998b1529c966",
        "id": "Utw7u7xJfbEd"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ваш поисковой запрос: уют\n",
            "Выбранный метод поиска: vector\n",
            "Количество результатов для выдачи: 5\n",
            "Время исполнения: 0.3845 секунд\n",
            "----------------------------------\n",
            "1. Скор:  0.7620\n",
            "Заглавие: Современная идиллия\n",
            "\n",
            "2. Скор:  0.7534\n",
            "Заглавие: Природа\n",
            "\n",
            "3. Скор:  0.7462\n",
            "Заглавие: Кадм и Гармония\n",
            "\n",
            "4. Скор:  0.7375\n",
            "Заглавие: Счастье\n",
            "\n",
            "5. Скор:  0.7367\n",
            "Заглавие: Красота\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perform_search(\"уют\", 5, 'hybrid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7916f878-bdd9-4e4b-de44-db622fb86b58",
        "id": "wh4pBViZfbEe"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Выполняется гибридный поиск...\n",
            "Выполняется полнотекстовый поиск...\n",
            "Предобработка текста: уют\n",
            "Полнотекстовый поиск завершен.\n",
            "Гибридный поиск завершен.\n",
            "\n",
            "Ваш поисковой запрос: уют\n",
            "Выбранный метод поиска: hybrid\n",
            "Количество результатов для выдачи: 5\n",
            "Время исполнения: 0.3413 секунд\n",
            "----------------------------------\n",
            "1. Скор:  0.3810\n",
            "Заглавие: Современная идиллия\n",
            "\n",
            "2. Скор:  0.3767\n",
            "Заглавие: Природа\n",
            "\n",
            "3. Скор:  0.3731\n",
            "Заглавие: Кадм и Гармония\n",
            "\n",
            "4. Скор:  0.3687\n",
            "Заглавие: Счастье\n",
            "\n",
            "5. Скор:  0.3684\n",
            "Заглавие: Красота\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Полный код запуска"
      ],
      "metadata": {
        "id": "MLVZzbrWeEY_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBMlFz1Zeq3z",
        "outputId": "59d04b7a-8696-4e5a-c2a8-18e207aa38e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Загрузка данных и моделей...\n",
            "Данные и модели загружены.\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import nltk\n",
        "import pymorphy2\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import joblib\n",
        "\n",
        "# загрузка необходимых ресурсов для обработки текста\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# инициализация морфологического анализатора и списка стоп-слов для русского\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "russian_stopwords = set(stopwords.words('russian'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Функция для предобработки текста:\n",
        "    1. Приведение к нижнему регистру.\n",
        "    2. Токенизация.\n",
        "    3. Нормализация слов с использованием морфологического анализатора.\n",
        "    4. Удаление стоп-слов.\n",
        "\n",
        "    :param text: Строка текста для обработки.\n",
        "    :return: Предобработанный текст.\n",
        "    \"\"\"\n",
        "    print(f\"Предобработка текста: {text}\")\n",
        "    words = nltk.word_tokenize(text.lower())\n",
        "    words = [morph.parse(word)[0].normal_form for word in words if word.isalnum()]\n",
        "    words = [word for word in words if word not in russian_stopwords]\n",
        "    return ' '.join(words)\n",
        "\n",
        "def full_text_search(query, top_k=5):\n",
        "    \"\"\"\n",
        "    Полнотекстовый поиск с использованием TF-IDF.\n",
        "\n",
        "    :param query: Поисковый запрос.\n",
        "    :param top_k: Количество возвращаемых результатов.\n",
        "    :return: Список кортежей (заголовок, оценка сходства).\n",
        "    \"\"\"\n",
        "    print(\"Выполняется полнотекстовый поиск...\")\n",
        "    processed_query = preprocess_text(query)\n",
        "    query_vec = vectorizer.transform([processed_query])\n",
        "    similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
        "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "    print(\"Полнотекстовый поиск завершен.\")\n",
        "    return [(data.iloc[i]['title'], similarities[i]) for i in top_indices]\n",
        "\n",
        "def get_embedding(text):\n",
        "    \"\"\"\n",
        "    Получение эмбеддинга текста с использованием модели sberbank-ai/sbert_large_nlu_ru.\n",
        "\n",
        "    :param text: Текст для преобразования в эмбеддинг.\n",
        "    :return: Эмбеддинг текста в виде numpy массива.\n",
        "    \"\"\"\n",
        "    print(f\"Получение эмбеддинга для: {text}\")\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=512\n",
        "    )\n",
        "    inputs = inputs.to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    print(\"Эмбеддинг получен.\")\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
        "\n",
        "def vector_search(query, top_k=5):\n",
        "    \"\"\"\n",
        "    Векторный поиск с использованием эмбеддингов.\n",
        "\n",
        "    :param query: Поисковый запрос.\n",
        "    :param top_k: Количество возвращаемых результатов.\n",
        "    :return: Список кортежей (заголовок, оценка сходства).\n",
        "    \"\"\"\n",
        "    print(\"Выполняется векторный поиск...\")\n",
        "    query_vec = get_embedding(query)\n",
        "    similarities = cosine_similarity([query_vec], sbert_embeddings).flatten()\n",
        "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "    print(\"Векторный поиск завершен.\")\n",
        "    return [(data.iloc[i]['title'], similarities[i]) for i in top_indices]\n",
        "\n",
        "def hybrid_search(query, top_k=5, weight_full_text=0.5):\n",
        "    \"\"\"\n",
        "    Гибридный поиск, комбинирующий полнотекстовый и векторный подходы.\n",
        "\n",
        "    :param query: Поисковый запрос.\n",
        "    :param top_k: Количество возвращаемых результатов.\n",
        "    :param weight_full_text: Вес для полнотекстового поиска в гибридной модели.\n",
        "    :return: Список кортежей (заголовок, комбинированная оценка сходства).\n",
        "    \"\"\"\n",
        "    print(\"Выполняется гибридный поиск...\")\n",
        "    full_text_results = full_text_search(query, top_k)\n",
        "    vector_results = vector_search(query, top_k)\n",
        "\n",
        "    combined_results = {}\n",
        "    for doc, score in full_text_results:\n",
        "        combined_results[doc] = weight_full_text * score\n",
        "\n",
        "    for doc, score in vector_results:\n",
        "        if doc in combined_results:\n",
        "            combined_results[doc] += (1 - weight_full_text) * score\n",
        "        else:\n",
        "            combined_results[doc] = (1 - weight_full_text) * score\n",
        "\n",
        "    sorted_results = sorted(combined_results.items(), key=lambda x: x[1], reverse=True)\n",
        "    print(\"Гибридный поиск завершен.\")\n",
        "    return sorted_results[:top_k]\n",
        "\n",
        "def perform_search(query, top_k, method):\n",
        "    \"\"\"\n",
        "    Основная функция для выполнения поиска по выбранному методу.\n",
        "\n",
        "    :param query: Поисковый запрос.\n",
        "    :param top_k: Количество возвращаемых результатов.\n",
        "    :param method: Метод поиска ('full_text', 'vector', 'hybrid').\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    if method == 'full_text':\n",
        "        results = full_text_search(query, top_k)\n",
        "    elif method == 'vector':\n",
        "        results = vector_search(query, top_k)\n",
        "    elif method == 'hybrid':\n",
        "        results = hybrid_search(query, top_k)\n",
        "    else:\n",
        "        raise ValueError(\"Неверный метод поиска. Выберите из 'full_text', 'vector', 'hybrid'.\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    # нумерация результатов и вывод\n",
        "    numbered_results = [(i + 1, doc, score) for i, (doc, score) in enumerate(results)]\n",
        "\n",
        "    print(f\"\\nВаш поисковой запрос: {query}\")\n",
        "    print(f\"Выбранный метод поиска: {method}\")\n",
        "    print(f\"Количество результатов для выдачи: {top_k}\")\n",
        "    print(f\"Время исполнения: {elapsed_time:.4f} секунд\")\n",
        "    print(\"-\" * 34)\n",
        "\n",
        "    for i, doc, score in numbered_results:\n",
        "        print(f\"{i}. Скор:  {score:.4f}\")\n",
        "        print(f\"Заглавие: {doc}\\n\")\n",
        "\n",
        "print(\"Загрузка данных и моделей...\")\n",
        "data = pd.read_csv('rus_novel_titles.csv')\n",
        "\n",
        "tfidf_matrix = joblib.load('tfidf_matrix.pkl')\n",
        "vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
        "sbert_embeddings = np.load('sbert_large_nlu_ru_embeddings.npy')\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/sbert_large_nlu_ru\")\n",
        "model = AutoModel.from_pretrained(\"sberbank-ai/sbert_large_nlu_ru\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(\"Данные и модели загружены.\")\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     parser = argparse.ArgumentParser(description='Поиск')\n",
        "#     parser.add_argument('--query', type=str, required=True, help='Поисковый запрос')\n",
        "#     parser.add_argument('--count', type=int, default=5, help='Количество возвращаемых результатов')\n",
        "#     parser.add_argument('--method', type=str, default='hybrid', choices=['full_text', 'vector', 'hybrid'], help='Метод поиска')\n",
        "#     args = parser.parse_args()\n",
        "\n",
        "#     perform_search(args.query, args.count, args.method)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perform_search(\"самолет\", 5, 'full_text')"
      ],
      "metadata": {
        "id": "lJATn2LTnCuh",
        "outputId": "b8732b68-91ba-4f6c-b6f0-3a5956537d64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ваш поисковой запрос: самолет\n",
            "Выбранный метод поиска: full_text\n",
            "Количество результатов для выдачи: 5\n",
            "Время исполнения: 0.0306 секунд\n",
            "----------------------------------\n",
            "1. Скор:  0.0000\n",
            "Заглавие: Моя весна\n",
            "\n",
            "2. Скор:  0.0000\n",
            "Заглавие: Идеалисты и реалисты\n",
            "\n",
            "3. Скор:  0.0000\n",
            "Заглавие: Царский суд\n",
            "\n",
            "4. Скор:  0.0000\n",
            "Заглавие: Мещане\n",
            "\n",
            "5. Скор:  0.0000\n",
            "Заглавие: Убийца\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perform_search(\"самолет\", 5, 'vector')"
      ],
      "metadata": {
        "id": "ZdlMTWYEmx6X",
        "outputId": "b469ef72-c981-4000-9da9-820e649bdce9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ваш поисковой запрос: самолет\n",
            "Выбранный метод поиска: vector\n",
            "Количество результатов для выдачи: 5\n",
            "Время исполнения: 0.3394 секунд\n",
            "----------------------------------\n",
            "1. Скор:  0.6831\n",
            "Заглавие: Ветер\n",
            "\n",
            "2. Скор:  0.6816\n",
            "Заглавие: Метеор\n",
            "\n",
            "3. Скор:  0.6807\n",
            "Заглавие: Крылья\n",
            "\n",
            "4. Скор:  0.6702\n",
            "Заглавие: Автомат\n",
            "\n",
            "5. Скор:  0.6557\n",
            "Заглавие: Капитон Перелетов\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perform_search(\"самолет\", 5, 'hybrid')"
      ],
      "metadata": {
        "id": "gniqBTXQnKfw",
        "outputId": "a6d7b986-9000-4d71-a9d7-7d394043f8c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Выполняется гибридный поиск...\n",
            "Выполняется полнотекстовый поиск...\n",
            "Предобработка текста: самолет\n",
            "Полнотекстовый поиск завершен.\n",
            "Выполняется векторный поиск...\n",
            "Получение эмбеддинга для: самолет\n",
            "Эмбеддинг получен.\n",
            "Векторный поиск завершен.\n",
            "Гибридный поиск завершен.\n",
            "\n",
            "Ваш поисковой запрос: самолет\n",
            "Выбранный метод поиска: hybrid\n",
            "Количество результатов для выдачи: 5\n",
            "Время исполнения: 10.5299 секунд\n",
            "----------------------------------\n",
            "1. Скор:  0.3023\n",
            "Заглавие: Капитон Перелетов\n",
            "\n",
            "2. Скор:  0.2759\n",
            "Заглавие: Новая метла\n",
            "\n",
            "3. Скор:  0.2717\n",
            "Заглавие: Метеор\n",
            "\n",
            "4. Скор:  0.2685\n",
            "Заглавие: Крылья\n",
            "\n",
            "5. Скор:  0.2657\n",
            "Заглавие: Корнет Отлетаев\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "ymg9mUyNFBsf",
        "3uArRuNUGtBo"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}